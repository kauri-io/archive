<!DOCTYPE html>
<html lang="en">
<head>
  
  
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    
    <link rel="canonical" href="https://kauri.io/collections/Build%20your%20very%20own%20self-hosting%20platform%20with%20Raspberry%20Pi%20and%20Kubernetes/%2858%29-self-host-your-media-center-on-kubernetes-wi/">
    <link rel="shortcut icon" href="../../../img/favicon.ico">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
    <title>(5/8) Self-host your Media Center On Kubernetes with Plex, Sonarr, Radarr, Transmission and Jackett - kauri.io</title>
    <link href="../../../css/bootstrap-3.3.7.min.css" rel="stylesheet">
    <link href="../../../css/font-awesome-4.7.0.css" rel="stylesheet">
    <link href="../../../css/base.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../css/highlight.css">
    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->

    <script src="../../../js/jquery-3.2.1.min.js"></script>
    <script src="../../../js/bootstrap-3.3.7.min.js"></script>
    <script src="../../../js/highlight.pack.js"></script>
    
    <base target="_top">
    <script>
      var base_url = '../../..';
      var is_top_frame = false;
        
        var pageToc = [
          {title: "(5/8) Self-host your Media Center On Kubernetes with Plex, Sonarr, Radarr, Transmission and Jackett", url: "#_top", children: [
              {title: "This article is part of the series Build your very own self-hosting platform with Raspberry Pi and Kubernetes", url: "#this-article-is-part-of-the-series-build-your-very-own-self-hosting-platform-with-raspberry-pi-and-kubernetes" },
              {title: "Introduction", url: "#introduction" },
              {title: "Namespace", url: "#namespace" },
              {title: "Persistence", url: "#persistence" },
              {title: "Ingress", url: "#ingress" },
              {title: "Heml Repository - add Bananaspliff", url: "#heml-repository-add-bananaspliff" },
              {title: "BitTorrent client - Transmission over VPN", url: "#bittorrent-client-transmission-over-vpn" },
              {title: "Torrent Providers Aggregator- Jackett over VPN", url: "#torrent-providers-aggregator-jackett-over-vpn" },
              {title: "TV Show Library Management - Sonarr", url: "#tv-show-library-management-sonarr" },
              {title: "Movie Library Management - Radarr", url: "#movie-library-management-radarr" },
              {title: "Media Server - Plex", url: "#media-server-plex" },
              {title: "Conclusion", url: "#conclusion" },
          ]},
        ];

    </script>
    <script src="../../../js/base.js"></script>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-172017815-1', 'kauri.io');
        ga('send', 'pageview');
    </script> 
</head>

<body>
<script>
if (is_top_frame) { $('body').addClass('wm-top-page'); }
</script>



<div class="container-fluid wm-page-content">
  <a name="_top"></a>
    

    <h1 id="58-self-host-your-media-center-on-kubernetes-with-plex-sonarr-radarr-transmission-and-jackett">(5/8) Self-host your Media Center On Kubernetes with Plex, Sonarr, Radarr, Transmission and Jackett<a class="headerlink" href="#58-self-host-your-media-center-on-kubernetes-with-plex-sonarr-radarr-transmission-and-jackett" title="Permanent link"></a></h1>
<p><img alt="" src="https://ipfs.infura.io/ipfs/QmUMQnRmFtNMXkBfYQdjG9WMCpAof49zavMNJXYHSDSa2k" /></p>
<p><br /></p>
<h4 id="this-article-is-part-of-the-series-build-your-very-own-self-hosting-platform-with-raspberry-pi-and-kubernetes">This article is part of the series <a href="https://kauri.io/build-your-very-own-self-hosting-platform-with-raspberry-pi-and-kubernetes/5e1c3fdc1add0d0001dff534/c">Build your very own self-hosting platform with Raspberry Pi and Kubernetes</a><a class="headerlink" href="#this-article-is-part-of-the-series-build-your-very-own-self-hosting-platform-with-raspberry-pi-and-kubernetes" title="Permanent link"></a></h4>
<ol>
<li><a href="https://kauri.io/build-your-very-own-self-hosting-platform-with-raspberry-pi-and-kubernetes-introduction/1229f21044ef4bff8df35875d6803776/a">Introduction</a></li>
<li><a href="https://kauri.io/install-raspbian-operating-system-and-prepare-the-system-for-kubernetes/7df2a9f9cf5f4f6eb217aa7223c01594/a">Install Raspbian Operating-System and prepare the system for Kubernetes</a></li>
<li><a href="https://kauri.io/install-and-configure-a-kubernetes-cluster-with-k3s-to-self-host-applications/418b3bc1e0544fbc955a4bbba6fff8a9/a">Install and configure a Kubernetes cluster with k3s to self-host applications</a></li>
<li><a href="https://kauri.io/deploy-nextcloud-on-kuberbetes:-the-self-hosted-dropbox/f958350b22794419b09fc34c7284b02e/a">Deploy NextCloud on Kuberbetes: The self-hosted Dropbox</a></li>
<li><strong>Self-host your Media Center On Kubernetes with Plex, Sonarr, Radarr, Transmission and Jackett</strong></li>
<li><a href="https://kauri.io/-selfhost-pihole-on-kubernetes-and-block-ads-and/5268e3daace249aba7db0597b47591ef/a">Self-host Pi-Hole on Kubernetes and block ads and trackers at the network level</a></li>
<li><a href="https://kauri.io/selfhost-your-password-manager-with-bitwarden/b2187730d4294626b28d1d938057e2e0/a">Self-host your password manager with Bitwarden</a></li>
<li><a href="https://kauri.io/deploy-prometheus-and-grafana-to-monitor-a-kube/186a71b189864b9ebc4ef7c8a9f0a6b5/a">Deploy Prometheus and Grafana to monitor a Kubernetes cluster</a></li>
</ol>
<p><br />
<br /></p>
<h3 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link"></a></h3>
<p>In the next article of this series, we will learn how to install and configure a Media Center onto our Kubernetes platform to automate the media aggregation and management and play our Media files. The Media Center will be composed of the following components:</p>
<ul>
<li><strong>Persistence:</strong> A dedicated volume on the SSD to store the data and files</li>
<li><strong>Torrent Proxy:</strong> Jackett is a Torrent Providers Aggregator tool helping to find efficiently BitTorent files over the web</li>
<li><strong>Downloaders:</strong> Transmission is a BitTorrent client to download the files</li>
<li><strong>TV Show/Movie Media Management:</strong> We'll use Sonarr and Radarr to automate the media aggregation. It searches, launches downloads and renames files when they go out</li>
<li><strong>Media Center/Player:</strong> Plex (server/player) will allow us to make our Media resources accessible from anywhere.</li>
</ul>
<p><img alt="" src="https://ipfs.infura.io/ipfs/Qmex8bC6gLPAHCmtAc2EHe3jnUYjXoV9GA5SFQFcrboqCu" /></p>
<p><br />
<br /></p>
<h3 id="namespace">Namespace<a class="headerlink" href="#namespace" title="Permanent link"></a></h3>
<p>We are going to isolate all the Kubernetes objects related to the Media Center into the namespace <code>media</code>.</p>
<p>To create a namespace, run the following command:</p>
<pre><code>$ kubectl create namespace media
</code></pre>
<p><br />
<br /></p>
<h3 id="persistence">Persistence<a class="headerlink" href="#persistence" title="Permanent link"></a></h3>
<p>The first step consists in setting up a volume to store our media files and data required to run each component. If you followed the previous articles to install and configure a self-hosting platform using RaspberryPi and Kubernetes, you remember we have on each worker a NFS client pointing to a SSD on <code>/mnt/ssd</code>.</p>
<p><strong>1. Deploy the Persistent Volume (PV)</strong></p>
<p>The Persistent Volume specifies the name, the size, the location and the access modes of the volume:</p>
<ul>
<li>The name of the PV is  <code>media-ssd</code></li>
<li>The size allocated is 200GB</li>
<li>The location is <code>/mnt/ssd/media</code></li>
<li>The access is ReadWriteOnce</li>
</ul>
<p>Create the following file and apply it to the k8 cluster.</p>
<pre><code class="language-yaml">## media.persistentvolume.yml
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: &quot;media-ssd&quot;
  labels:
    type: &quot;local&quot;
spec:
  storageClassName: &quot;manual&quot;
  capacity:
    storage: &quot;200Gi&quot;
  accessModes:
    - ReadWriteMany
  hostPath:
    path: &quot;/mnt/ssd/media&quot;
---
</code></pre>
<pre><code>$ kubectl apply -f media.persistentvolume.yml
persistentvolume/media-ssd created
</code></pre>
<p>You can verify the PV exists with the following command:</p>
<pre><code>$ kubectl get pv

NAME            CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS      CLAIM   STORAGECLASS   REASON   AGE
media-ssd       200Gi      RWO            Retain           Available           manual                  34s
</code></pre>
<p><br />
<strong>2. Create the Persistent Volume Claim (PVC)</strong></p>
<p>The Persistent Volume Claim is used to map a Persistent Volume to a deployment or stateful set. Unlike the PV, the PVC belongs to a namespace.</p>
<p>Create the following file and apply it to the k8 cluster.</p>
<pre><code class="language-yaml">## media.persistentvolumeclaim.yml
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  namespace: &quot;media&quot;
  name: &quot;media-ssd&quot;
spec:
  storageClassName: &quot;manual&quot;
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: &quot;200Gi&quot;
---
</code></pre>
<pre><code>$ kubectl apply -f media.persistentvolumeclaim.yml
persistentvolumeclaim/media-ssd created
</code></pre>
<p>You can verify the PVC exists with the following command:</p>
<pre><code>$ kubectl get pvc -n media

NAME            STATUS   VOLUME          CAPACITY   ACCESS MODES   STORAGECLASS   AGE
media-ssd       Bound    media-ssd       200Gi      RWO            manual         26s
</code></pre>
<p><br />
<br /></p>
<h3 id="ingress">Ingress<a class="headerlink" href="#ingress" title="Permanent link"></a></h3>
<p>After the persistent volume, we are now going to deploy the ingress responsible of making accessible a service from outside the cluster by mapping an internal <code>service:port</code> to a host. To choose a host, we need to configure a DNS like we did for NextCloud "nextcloud.<domain.com>" in the previous article. However, unlike NextCloud, the Media Center components have no reason to be exposed on the Internet, we can pick a host that will be resolved internally to our Nginx proxy (available at <code>192.168.0.240</code> : LoadBalancer IP). The simplest solution is to use <a href="https://nip.io">nip.io</a> which allows us to map an IP (in our case <code>192.168.0.240</code>) to a hostname without touching <code>/etc/hosts</code> or configuring a DNS. Basically it resolves <code>&lt;anything&gt;.&lt;ip&gt;.nip.io</code> by <code>&lt;ip&gt;</code> without requiring anything else, Magic !</p>
<p><strong>1. Create the file <code>media.ingress.yaml</code></strong></p>
<p>Create the following Ingress config file <code>media.ingress.yaml</code> to map the routes to each service we will deploy right after this step:</p>
<ul>
<li><code>http://media.192.168.0.240.nip.io/transmission</code> -&gt; <code>transmission-transmission-openvpn:80</code></li>
<li><code>http://media.192.168.0.240.nip.io/sonarr</code> -&gt; <code>sonarr:80</code></li>
<li><code>http://media.192.168.0.240.nip.io/jackett</code> -&gt; <code>jackett:80</code></li>
<li><code>http://media.192.168.0.240.nip.io/radarr</code> -&gt; <code>radarr:80</code></li>
<li><code>http://media.192.168.0.240.nip.io/</code> -&gt; <code>plex-kube-plex:32400</code></li>
</ul>
<pre><code class="language-yaml">## media.ingress.yaml
---
apiVersion: extensions/v1beta1
kind: Ingress
metadata:
  namespace: &quot;media&quot;
  name: &quot;media-ingress&quot;
spec:
  rules:
  - host: &quot;media.192.168.0.240.nip.io&quot;
    http:
      paths:
        - backend:
            serviceName: &quot;transmission-transmission-openvpn&quot;
            servicePort: 80
          path: &quot;/transmission&quot;
        - backend:
            serviceName: &quot;sonarr&quot;
            servicePort: 80
          path: &quot;/sonarr&quot;
        - backend:
            serviceName: &quot;jackett&quot;
            servicePort: 80
          path: &quot;/jackett&quot;
        - backend:
            serviceName: &quot;radarr&quot;
            servicePort: 80
          path: &quot;/radarr&quot;
        - backend:
            serviceName: &quot;plex-kube-plex&quot;
            servicePort: 32400
          path: &quot;/&quot;
---
</code></pre>
<p><br />
<strong>2. Deploy the ingress</strong></p>
<p>Deploy the Ingress by applying the file <code>media.ingress.yaml</code>.</p>
<pre><code>$ kubectl apply -f media.ingress.yaml
ingress.extensions/media-ingress created
</code></pre>
<p><br />
<strong>3. Confirm the Ingress is correctly deployed</strong></p>
<p>Try the URL <a href="http://media.192.168.0.240.nip.io">http://media.192.168.0.240.nip.io</a> from your browser and confirm it returns the error message <code>503 Service Temporarily Unavailable</code> which is normal because we haven't deployed anything yet.</p>
<p><img alt="" src="https://i.imgur.com/tIC7P0r.png" /></p>
<p><br />
<br /></p>
<h3 id="heml-repository-add-bananaspliff">Heml Repository - add Bananaspliff<a class="headerlink" href="#heml-repository-add-bananaspliff" title="Permanent link"></a></h3>
<p>Someone already made a very good job at creating specific <a href="https://bananaspliff.github.io/geek-charts/">Helm Charts</a> for the all the software we wish to install in this tutorial. Add the following repository to your Helm using the following command:</p>
<pre><code>$ helm repo add bananaspliff https://bananaspliff.github.io/geek-charts
$ helm repo update
</code></pre>
<p><br />
<br /></p>
<p><img alt="" src="https://ipfs.infura.io/ipfs/QmTp1hoJ558ZtTRXDtsmj6smFJLq2y6J8d7a5MD6gmPzfH" /></p>
<p><br /></p>
<h3 id="bittorrent-client-transmission-over-vpn">BitTorrent client - Transmission over VPN<a class="headerlink" href="#bittorrent-client-transmission-over-vpn" title="Permanent link"></a></h3>
<p>The first bit of software to install is <a href="https://transmissionbt.com">Transmission</a>, an open-source BitTorent client offering an API, great for integration and automation. Because many Internet providers and Governments disproves BitTorent download, we are going to deploy Transmission alongside a VPN. The image <a href="https://haugene.github.io/docker-transmission-openvpn/">haugene/transmission-openvpn</a> includes Transmission and supports a very large range of VPN providers (see <a href="https://haugene.github.io/docker-transmission-openvpn/supported-providers/">here</a>) to obfuscate the traffic. I will be using NordVPN but change appropriately to your need.</p>
<p><br />
<strong>1. Create a Kubernetes secret to store your VPN password</strong></p>
<p>We first need to safely store our VPN Provider username and password into a <a href="https://kubernetes.io/docs/concepts/configuration/secret/">Kubernetes secret</a>. Run the command using your own VPN username and password:</p>
<pre><code>$ kubectl create secret generic openvpn \
    --from-literal='username=&lt;VPN_USERNAME&gt;' \
    --from-literal='password=&lt;VPN_PASSWORD&gt;' \
    --namespace media
</code></pre>
<p><br />
<strong>2. Write the Helm configuration</strong></p>
<p>Next, we will configure the chart <a href="https://github.com/bananaspliff/geek-charts/tree/gh-pages/transmission-openvpn">bananaspliff/transmission-openvpn</a>. The default configuration can be seen by running the following command <code>$ helm show values bananaspliff/transmission-openvpn</code>.</p>
<p>Create the file <code>media.transmission-openvpn.values.yml</code> containing the following configuration.</p>
<pre><code class="language-yaml">## media.transmission-openvpn.values.yml
replicaCount: 1

image:
  repository: &quot;haugene/transmission-openvpn&quot;
  tag: &quot;latest-armhf&quot; # Suffixed by -armhf to pull the ARM image
  pullPolicy: &quot;IfNotPresent&quot;

env:
  - name: OPENVPN_PROVIDER
    value: &quot;NORDVPN&quot; # VPN provider. List of supported providers: https://haugene.github.io/docker-transmission-openvpn/supported-providers/
  - name: OPENVPN_USERNAME
    valueFrom: # Reference to the secret | openvpn.username
      secretKeyRef:
        name: &quot;openvpn&quot;
        key: &quot;username&quot;
  - name: OPENVPN_PASSWORD
    valueFrom: # Reference to the secret | openvpn.password
      secretKeyRef:
        name: &quot;openvpn&quot;
        key: &quot;password&quot;
  - name: NORDVPN_PROTOCOL
    value: &quot;TCP&quot;
  - name: NORDVPN_COUNTRY
    value: &quot;CH&quot; # Country where we want to download over VPN
  - name: NORDVPN_CATEGORY
    value: &quot;P2P&quot; # VPN Type
  - name: LOCAL_NETWORK
    value: &quot;192.168.0.0/24&quot;
  - name: TRANSMISSION_PEER_PORT
    value: &quot;47444&quot;
  - name: TRANSMISSION_DOWNLOAD_DIR
    value: &quot;/downloads/transmission&quot;
  - name: PUID
    value: &quot;1000&quot;
  - name: PGID
    value: &quot;1000&quot;

service:
  type: ClusterIP
  port: 80

volumes:
  - name: &quot;media-ssd&quot;
    persistentVolumeClaim:
      claimName: &quot;media-ssd&quot; # PersistentVolumeClaim created earlier
  - name: &quot;dev-tun&quot; # Needed for VPN
    hostPath:
      path: &quot;/dev/net/tun&quot;

volumeMounts:
  - name: &quot;media-ssd&quot;
    mountPath: &quot;/data&quot;
    subPath: &quot;configs/transmission-data&quot; # Path /mnt/ssd/media/configs/transmission-data where transmission writes the configuration
  - name: &quot;media-ssd&quot;
    mountPath: &quot;/downloads/transmission&quot;
    subPath: &quot;downloads/transmission&quot; # Path /mnt/ssd/media/downloads/transmission where transmission downloads Torrents
  - name: &quot;dev-tun&quot;
    mountPath: &quot;/dev/net/tun&quot; # Needed for VPN

securityContext:
  capabilities: # Needed for VPN
    add:
      - NET_ADMIN
</code></pre>
<p><br />
<strong>2. Install the chart <code>bananaspliff/transmission-openvpn</code></strong></p>
<p>Execute the following command to install the chart <code>bananaspliff/transmission-openvpn</code> with the above configuration onto the namespace <code>media</code>.</p>
<pre><code>$ helm install transmission bananaspliff/transmission-openvpn \
    --values media.transmission-openvpn.values.yml \
    --namespace media
</code></pre>
<p>After a couple of minutes, you should observe a pod named <code>transmission-transmission-openvpn-xxx</code> Running.</p>
<pre><code>$ kubectl get pods -n media -l app=transmission-openvpn -o wide

NAME                                                 READY   STATUS    RESTARTS   AGE   IP           NODE           NOMINATED NODE   READINESS GATES
transmission-transmission-openvpn-8446dbf97c-rzw5l   1/1     Running   0          29m   10.42.1.26   kube-worker1   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p><br />
<strong>3. Access to Transmission Web console</strong></p>
<p>Now Transmission and the Nginx Ingress routes are deployed, you should be able to access the Transmission Web console via <a href="http://media.192.168.0.240.nip.io/transmission">http://media.192.168.0.240.nip.io/transmission</a>.</p>
<p><img alt="" src="https://i.imgur.com/qBAFOA1.png" /></p>
<p><br />
<br /></p>
<p><img alt="" src="https://ipfs.infura.io/ipfs/QmNsoV9jUjVJVz4dw9RVFUy8N6Q6rsZAHvHXk6aooMnZAZ" /></p>
<p><br /></p>
<h3 id="torrent-providers-aggregator-jackett-over-vpn">Torrent Providers Aggregator- Jackett over VPN<a class="headerlink" href="#torrent-providers-aggregator-jackett-over-vpn" title="Permanent link"></a></h3>
<p><a href="https://github.com/Jackett/Jackett">Jackett</a> is a Torrent Providers Aggregator which translates search queries from applications like Sonarr or Radarr into tracker-site-specific http queries, parses the html response, then sends results back to the requesting software. Because some Internet Providers might also block access to Torrent websites, I packaged a version of Jackett using a VPN connection (similar to <em>transmission-over-vpn</em>) accessible on <a href="https://hub.docker.com/repository/docker/gjeanmart/jackettvpn">Docker hub - gjeanmart/jackettvpn:latest-armhf</a>.</p>
<p><br />
<strong>1. Write the Helm configuration</strong></p>
<p>Let's now configure the chart <a href="https://github.com/bananaspliff/geek-charts/tree/gh-pages/jackett">bananaspliff/jackett</a>. The default configuration can be seen by running the following command <code>$ helm show values bananaspliff/jackett</code>.</p>
<p>Create the file <code>media.jackett.values.yml</code> containing the following configuration.</p>
<pre><code class="language-yaml">## media.jackett.values.yml
replicaCount: 1

image:
  repository: &quot;gjeanmart/jackettvpn&quot; # Special image to use Jackett over a VPN
  tag: &quot;latest-armhf&quot;
  pullPolicy: IfNotPresent

env:
  - name: VPN_ENABLED
    value: &quot;yes&quot; # Enable Jackett over VPN
  - name: VPN_USERNAME
    valueFrom:
      secretKeyRef: # Reference to the secret | openvpn.username
        name: &quot;openvpn&quot;
        key: &quot;username&quot;
  - name: VPN_PASSWORD
    valueFrom:
      secretKeyRef: # Reference to the secret | openvpn.password
        name: &quot;openvpn&quot;
        key: &quot;password&quot;
  - name: LAN_NETWORK
    value: &quot;192.168.0.0/24&quot;
  - name: CREATE_TUN_DEVICE
    value: &quot;true&quot; # Needed for VPN
  - name: PUID
    value: &quot;1000&quot;
  - name: PGID
    value: &quot;1000&quot;

service:
  type: ClusterIP
  port: 80

volumes:
  - name: &quot;media-ssd&quot;
    persistentVolumeClaim:
      claimName: &quot;media-ssd&quot; # PersistentVolumeClaim created earlier
  - name: &quot;dev-tun&quot;  # Needed for VPN
    hostPath:
      path: &quot;/dev/net/tun&quot;

volumeMounts:
  - name: &quot;media-ssd&quot;
    mountPath: &quot;/config&quot;
    subPath: &quot;configs/jackett&quot; # Path /mnt/ssd/media/configs/jackett where jackett writes the configuration
  - name: &quot;media-ssd&quot;
    mountPath: &quot;/downloads&quot;
    subPath: &quot;downloads/jackett&quot; # Path /mnt/ssd/media/downloads/jackett ???

securityContext:
  capabilities: # Needed for VPN
    add:
      - NET_ADMIN
</code></pre>
<p><br />
*<em>2. Configure VPN (only if you configured VPN_ENABLED=yes)</em></p>
<p>a. Create the following directory structure on your SSD</p>
<pre><code class="language-shell">$ mkdir -p /mnt/ssd/media/configs/jackett/openvpn/
</code></pre>
<p>b. Copy one OpenVPN file (usually provided by your VPN provider) into the folder <code>/mnt/ssd/media/configs/jackett/openvpn/</code></p>
<p>c. Create a file <code>credentials.conf</code> into the folder <code>/mnt/ssd/media/configs/jackett/openvpn/</code> composed of two line (first one: username and second one password)</p>
<pre><code>&lt;VPN_USERNAME&gt;
&lt;VPN_PASSWORD&gt;
</code></pre>
<p><strong>3. Pre-configure Jackett</strong></p>
<p>a. Create the following directory structure on your SSD</p>
<pre><code class="language-shell">$ mkdir -p /mnt/ssd/media/configs/jackett/Jackett/
</code></pre>
<p>b. Create the file <code>ServerConfig.json</code> into the folder <code>/mnt/ssd/media/configs/jackett/Jackett/</code> with the following content:</p>
<pre><code class="language-json">{
  &quot;BasePathOverride&quot;: &quot;/jackett&quot;
}
</code></pre>
<p><br />
<strong>4. Install the chart <code>bananaspliff/jackett</code></strong></p>
<p>Execute the following command to install the chart <code>bananaspliff/jackett</code> with the above configuration onto the namespace <code>media</code>.</p>
<pre><code>$ helm install jackett bananaspliff/jackett \
    --values media.jackett.values.yml \
    --namespace media
</code></pre>
<p>After a couple of minutes, you should observe a pod named <code>jackett-xxx</code> Running.</p>
<pre><code>$ kubectl get pods -n media -l app=jackett -o wide

NAME                      READY   STATUS    RESTARTS   AGE    IP           NODE           NOMINATED NODE   READINESS GATES
jackett-864697466-69xwt   1/1     Running   0          101s   10.42.1.29   kube-worker1   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p><br />
<strong>5. Access Jackett</strong></p>
<p>Go to Jackett on <a href="http://media.192.168.0.240.nip.io/jackett">http://media.192.168.0.240.nip.io/jackett</a> and try to add one or more indexers.</p>
<p><img alt="" src="https://i.imgur.com/IglUSIZ.png" /></p>
<p><br />
<br /></p>
<p><img alt="" src="https://ipfs.infura.io/ipfs/QmXrpHKsVCnsFQpzhprH1TYdBbyZaxssjy8hv34XkybULz" /></p>
<p><br /></p>
<h3 id="tv-show-library-management-sonarr">TV Show Library Management - Sonarr<a class="headerlink" href="#tv-show-library-management-sonarr" title="Permanent link"></a></h3>
<p><a href="https://sonarr.tv/">Sonarr</a> is a TV Show library management tool that offers multiple features:</p>
<ul>
<li>List all your episodes and see what's missing</li>
<li>See upcoming episodes</li>
<li>Automatically search last released episodes (via Jackett) and launch download (via Transmission)</li>
<li>Move downloaded files into the right directory</li>
<li>Notify when a new episodes is ready (Kodi, Plex)</li>
</ul>
<p><br />
<strong>1. Write the Helm configuration</strong></p>
<p>Let's now configure the chart <a href="https://github.com/bananaspliff/geek-charts/tree/gh-pages/sonarr">bananaspliff/sonarr</a>. The default configuration can be seen by running the following command <code>$ helm show values bananaspliff/sonarr</code>.</p>
<p>Create the file <code>media.sonarr.values.yml</code> containing the following configuration.</p>
<pre><code class="language-yaml">### media.sonarr.values.yml
replicaCount: 1

image:
  repository: linuxserver/sonarr
  tag: arm32v7-latest # ARM image
  pullPolicy: IfNotPresent

env:
  - name: PUID
    value: &quot;1000&quot;
  - name: PGID
    value: &quot;1000&quot;

service:
  type: ClusterIP
  port: 80

volumes:
  - name: media-ssd
    persistentVolumeClaim:
      claimName: &quot;media-ssd&quot; # PersistentVolumeClaim created earlier

volumeMounts:
  - name: media-ssd
    mountPath: &quot;/config&quot;
    subPath: &quot;configs/sonarr&quot; # Path /mnt/ssd/media/configs/sonarr where sonarr writes the configuration
  - name: media-ssd
    mountPath: &quot;/downloads/transmission&quot;
    subPath: &quot;downloads/transmission&quot; # Path /mnt/ssd/media/downloads/transmission where sonarr picks up downloaded episodes
  - name: media-ssd
    mountPath: &quot;/tv&quot;
    subPath: &quot;library/tv&quot; # Path /mnt/ssd/media/library/tv where sonarr moves and renames the episodes
</code></pre>
<p><br />
<strong>2. Pre-configure Sonarr</strong></p>
<p>a. Create the following directory structure on your SSD</p>
<pre><code class="language-shell">$ mkdir -p /mnt/ssd/media/configs/sonarr/
</code></pre>
<p>b. Create the file <code>config.xml</code> into the folder <code>/mnt/ssd/media/configs/sonarr/</code> with the following content:</p>
<pre><code class="language-xml">&lt;Config&gt;
  &lt;UrlBase&gt;/sonarr&lt;/UrlBase&gt;
&lt;/Config&gt;
</code></pre>
<p><br />
<strong>3. Install the chart <code>bananaspliff/sonarr</code></strong></p>
<p>Execute the following command to install the chart <code>bananaspliff/sonarr</code> with the above configuration onto the namespace <code>media</code>.</p>
<pre><code>$ helm install sonarr bananaspliff/sonarr \
    --values media.sonarr.values.yml \
    --namespace media
</code></pre>
<p>After a couple of minutes, you should observe a pod named <code>sonarr-xxx</code> Running.</p>
<pre><code>$ kubectl get pods -n media -l app=sonarr -o wide

NAME                      READY   STATUS    RESTARTS   AGE     IP           NODE           NOMINATED NODE   READINESS GATES
sonarr-574c5f85d7-n9jc6   1/1     Running   0          3m13s   10.42.1.30   kube-worker1   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p><br />
<strong>4. Access Sonarr</strong></p>
<p>Go to Sonarr on <a href="http://media.192.168.0.240.nip.io/sonarr">http://media.192.168.0.240.nip.io/sonarr</a> and start setting up the library automation. Refer to the <a href="https://github.com/Sonarr/Sonarr/wiki">wiki</a> for more details.</p>
<p><img alt="" src="https://i.imgur.com/HMzjbcm.png" /></p>
<ul>
<li>Configure the connection to Transmission into <strong>Settings / Download Client / Add (Transmission)</strong> using the hostname and port <code>transmission-transmission-openvpn.media:80</code></li>
</ul>
<p><img alt="" src="https://i.imgur.com/cWN5WKY.png" /></p>
<ul>
<li>Configure the connection to Jackett into <strong>Settings / Indexers / Add (Torznab / Custom)</strong> using the hostname and port <code>jackett.media:80</code></li>
</ul>
<p><img alt="" src="https://i.imgur.com/TFvpjYa.png" /></p>
<p><br />
<br /></p>
<p><img alt="" src="https://ipfs.infura.io/ipfs/QmXoFr3jf7GxTXtg5ezY1RKbUDjNiGXBhF2cbwwFYetNSk" /></p>
<p><br /></p>
<h3 id="movie-library-management-radarr">Movie Library Management - Radarr<a class="headerlink" href="#movie-library-management-radarr" title="Permanent link"></a></h3>
<p><a href="https://radarr.video/">Radarr</a> is a Movie library management tool that offers multiple features:</p>
<ul>
<li>List all your movies</li>
<li>Search movies (via Jackett) and launch download (via Transmission)</li>
<li>Move downloaded files into the right directory</li>
<li>Notify when a new movie is ready (Kodi, Plex)</li>
</ul>
<p><br />
<strong>1. Write the Helm configuration</strong></p>
<p>Let's now configure the chart <a href="https://github.com/bananaspliff/geek-charts/tree/gh-pages/radarr">bananaspliff/radarr</a>. The default configuration can be seen by running the following command <code>$ helm show values bananaspliff/radarr</code>.</p>
<p>Create the file <code>media.radarr.values.yml</code> containing the following configuration.</p>
<pre><code class="language-yaml">## media.radarr.values.yml
replicaCount: 1

image:
  repository: &quot;linuxserver/radarr&quot;
  tag: &quot;arm32v7-latest&quot; # ARM image
  pullPolicy: IfNotPresent

env:
  - name: PUID
    value: &quot;1000&quot;
  - name: PGID
    value: &quot;1000&quot;

service:
  type: ClusterIP
  port: 80

volumes:
  - name: &quot;media-ssd&quot;
    persistentVolumeClaim:
      claimName:  &quot;media-ssd&quot; # PersistentVolumeClaim created earlier

volumeMounts:
  - name: &quot;media-ssd&quot;
    mountPath: &quot;/config&quot;
    subPath: &quot;configs/radarr&quot; # Path /mnt/ssd/media/configs/radarr where radarr writes the configuration
  - name: &quot;media-ssd&quot;
    mountPath: &quot;/downloads/transmission&quot;
    subPath: &quot;downloads/transmission&quot; # Path /mnt/ssd/media/downloads/transmission where radarr picks up downloaded movies
  - name: media-ssd
    mountPath: &quot;/movies&quot;
    subPath: &quot;library/movies&quot; # Path /mnt/ssd/media/library/movies where radarr moves and renames the movies
</code></pre>
<p><br />
<strong>2. Pre-configure Radarr</strong></p>
<p>a. Create the following directory structure on your SSD</p>
<pre><code class="language-shell">$ mkdir -p /mnt/ssd/media/configs/radarr/
</code></pre>
<p>b. Create the file <code>config.xml</code> into the folder <code>/mnt/ssd/media/configs/radarr/</code> with the following content:</p>
<pre><code class="language-xml">&lt;Config&gt;
  &lt;UrlBase&gt;/radarr&lt;/UrlBase&gt;
&lt;/Config&gt;
</code></pre>
<p><br />
<strong>3. Install the chart <code>bananaspliff/radarr</code></strong></p>
<p>Execute the following command to install the chart <code>bananaspliff/radarr</code> with the above configuration onto the namespace <code>media</code>.</p>
<pre><code>$ helm install radarr bananaspliff/radarr \
    --values media.radarr.values.yml \
    --namespace media
</code></pre>
<p>After a couple of minutes, you should observe a pod named <code>radarr-xxx</code> Running.</p>
<pre><code>$  kubectl get pods -n media -l app=radarr -o wide

NAME                      READY   STATUS    RESTARTS   AGE   IP          NODE           NOMINATED NODE   READINESS GATES
radarr-7846697889-jhqbz   1/1     Running   0          11m   10.42.2.2   kube-worker2   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p><br />
<strong>4. Access Radarr</strong></p>
<p>Go to Radarr on <a href="http://media.192.168.0.240.nip.io/radarr">http://media.192.168.0.240.nip.io/radarr</a> and start setting up the library automation. Refer to the <a href="https://github.com/Radarr/Radarr/wiki">wiki</a> for more details.</p>
<p><img alt="" src="https://i.imgur.com/gqCB8TX.png" /></p>
<p><br />
<br /></p>
<p><img alt="" src="https://ipfs.infura.io/ipfs/QmbASTjZAenaVQ3FGg9oGRSjo1PZVG5JwjjKkdRSFPzaEu" /></p>
<p><br /></p>
<h3 id="media-server-plex">Media Server - Plex<a class="headerlink" href="#media-server-plex" title="Permanent link"></a></h3>
<p><a href="https://www.plex.tv/en-gb/">Plex Media Server</a> is a software to serve and stream your personal Media library (movies, TV show and music). It fetches the Media resources and builds up a catalogue accessible to any compatible players (Desktop/Mobiles) and transcodes the stream to the player.</p>
<p><br /></p>
<p>In this section, we are going to deploy Plex Media Server (PMS) on Kubernetes using the Helm chart <a href="https://github.com/munnerz/kube-plex">kube-plex</a>.</p>
<p><strong>1. Clone the charts</strong></p>
<p>This Helm chart is not available via an online repository like jetstack or bananaspliff. We need to download the chart locally. Clone the following repository using <code>git</code>.</p>
<pre><code>$ git clone https://github.com/munnerz/kube-plex.git
</code></pre>
<p><br />
<strong>2. Get a claim token</strong></p>
<p>Obtain a Plex Claim Token by visiting <a href="https://plex.tv/claim">plex.tv/claim</a>. You need to create an account if you haven't already one yet.</p>
<p>This will be used to bind your new PMS instance to your own user account automatically.</p>
<p><img alt="" src="https://i.imgur.com/VLScSRw.png" /></p>
<p><br />
<strong>3. Create the Helm config file <code>media.plex.values.yml</code></strong></p>
<pre><code class="language-yaml">## media.plex.values.yml

claimToken: &quot;&lt;CLAIM_TOKEN&gt;&quot; # Replace `&lt;CLAIM_TOKEN&gt;` by the token obtained previously.

image:
  repository: linuxserver/plex
  tag: arm32v7-latest
  pullPolicy: IfNotPresent

kubePlex:
  enabled: false # kubePlex (transcoder job) is disabled because not available on ARM. The transcoding will be performed by the main Plex instance instead of a separate Job.

timezone: Europe/London

service:
  type: LoadBalancer # We will use a LoadBalancer to obtain a virtual IP that can be exposed to Plex Media via our router
  port: 32400 # Port to expose Plex

rbac:
  create: true

nodeSelector: {}

persistence:
  transcode:
    claimName: &quot;media-ssd&quot;
  data:
    claimName: &quot;media-ssd&quot;
  config:
    claimName: &quot;media-ssd&quot;

resources: {}
podAnnotations: {}
proxy:
  enable: false
</code></pre>
<p><br />
<strong>4. Install Plex using Helm</strong></p>
<p>Now install Plex with Helm specifying our config file <code>media.plex.values.yml</code> and the namespace <code>media</code>:</p>
<pre><code>$ helm install plex kube-plex/charts/kube-plex/ \
  --values media.plex.values.yml \
  --namespace media
</code></pre>
<p>Wait until <code>kube-plex</code> (Plex Media Server) is up and running.</p>
<pre><code>$ kubectl get pods -n media -l app=kube-plex -o wide

NAME                             READY   STATUS    RESTARTS   AGE   IP           NODE          NOMINATED NODE   READINESS GATES
plex-kube-plex-b76f8f478-4tn97   1/1     Running   0          55s   10.42.0.27   kube-master   &lt;none&gt;           &lt;none&gt;
</code></pre>
<p>You can find the Virtual IP attributed to Plex by MetalLB (in my case <code>192.168.0.241</code>).</p>
<pre><code>$ kubectl get services -n media -l app=kube-plex -o wide

NAME             TYPE           CLUSTER-IP    EXTERNAL-IP     PORT(S)                                      AGE   SELECTOR
plex-kube-plex   LoadBalancer   10.43.77.73   192.168.0.241   32400:30048/TCP,80:32383/TCP,443:31274/TCP   16m   app=kube-plex,release=plex
</code></pre>
<p><br />
<strong>5. Router config (outside access only)</strong></p>
<p>If you want to access remotely to your Media library, you will need to configure a port-forwarding to allow Plex to access your PMS.</p>
<p>Add a route to port-forward incoming requests on port <code>32400</code> to <code>192.168.0.241:32400</code> (Plex virtual IP assigned by MetalLB).</p>
<p><img alt="" src="https://i.imgur.com/A0rmhfH.png" /></p>
<p><br />
<strong>6. Setup Plex</strong></p>
<p>Try now to access (from your network) to Plex Web Player on <a href="http://192.168.0.241:32400/">http://192.168.0.241:32400</a>. You should see the setup wizard :</p>
<ul>
<li>Click on <em>Got It</em></li>
</ul>
<p><img alt="" src="https://i.imgur.com/eMqahAZ.png" /></p>
<ul>
<li>Select <em>Next</em></li>
</ul>
<p>You can uncheck <em>Allow me to access my media outside my home</em> if you only want to use Plex within your home network.</p>
<p><img alt="" src="https://i.imgur.com/ActauD5.png" /></p>
<ul>
<li>Configure the different Libraries (movies, tv shows, music, etc.)</li>
</ul>
<p>Our Media will be accessible from the folder <code>/data/</code>.</p>
<p><img alt="" src="https://i.imgur.com/lU9g43e.png" /></p>
<ul>
<li>Click on <em>Done</em></li>
</ul>
<p><img alt="" src="https://i.imgur.com/lvbswJK.png" /></p>
<ul>
<li>All set! Plex will start scrapping your library (bear in mind, this can take a while)</li>
</ul>
<p><img alt="" src="https://i.imgur.com/5ABd3Rw.jpg" /></p>
<ul>
<li>For outside access, you need to configure the external port used to map outside incoming requests to Plex. Go to <em>Settings / Remote Access</em> and check <em>Manually specify the public</em> to set the port <code>32400</code> (as configured in the router - Local)</li>
</ul>
<p><img alt="" src="https://i.imgur.com/64ntDcS.png" /></p>
<p><br />
<strong>Notes</strong></p>
<ul>
<li>You can also access Plex from your local network via the ingress: <a href="http://media.192.168.0.240.nip.io/web">http://media.192.168.0.240.nip.io/web</a></li>
<li>Download the Android/iOS app and connect to your Plex account, you should automatically see your Plex Media Server with our your Media.</li>
</ul>
<p><br />
<br /></p>
<h3 id="conclusion">Conclusion<a class="headerlink" href="#conclusion" title="Permanent link"></a></h3>
<p>In conclusion, you now have everything you need to automate and manage your Media and enjoy watching shows, movies or just listen some music !</p>
<p><br />
<br /></p>
<hr />
<ul>
<li><strong>Kauri original title:</strong> (5/8) Self-host your Media Center On Kubernetes with Plex, Sonarr, Radarr, Transmission and Jackett</li>
<li><strong>Kauri original link:</strong> https://kauri.io/58-selfhost-your-media-center-on-kubernetes-with-p/8ec7c8c6bf4e4cc2a2ed563243998537/a</li>
<li><strong>Kauri original author:</strong> Grégoire Jeanmart (@gregjeanmart)</li>
<li><strong>Kauri original Publication date:</strong> 2020-05-26</li>
<li><strong>Kauri original tags:</strong> self-hosting, kubernetes, tv-show, k8s, plex, bittorrent, htpc</li>
<li><strong>Kauri original hash:</strong> QmWcNJUeEMcNMrBb6CUqg6egT6tmsZWiaJSU3rPY3V5bL8</li>
<li><strong>Kauri original checkpoint:</strong> unknown</li>
</ul>

  <br>
    

    
    
      
    

  <div class="row wm-article-nav-buttons" role="navigation" aria-label="navigation">
    
    <div class="wm-article-nav pull-right">
      <a href="../%2868%29-self-host-pi-hole-on-kubernetes-and-block-ad/" class="btn btn-xs btn-default pull-right">
        Next
        <i class="fa fa-chevron-right" aria-hidden="true"></i>
      </a>
      <a href="../%2868%29-self-host-pi-hole-on-kubernetes-and-block-ad/" class="btn btn-xs btn-link">
        (6/8) Self-host Pi-Hole on Kubernetes and block ads and trackers at the network level
      </a>
    </div>
    
    <div class="wm-article-nav">
      <a href="../%2848%29-deploy-nextcloud-on-kuberbetes--the-self-hos/" class="btn btn-xs btn-default pull-left">
        <i class="fa fa-chevron-left" aria-hidden="true"></i>
        Previous</a><a href="../%2848%29-deploy-nextcloud-on-kuberbetes--the-self-hos/" class="btn btn-xs btn-link">
        (4/8) Deploy NextCloud on Kuberbetes  The self-hosted Dropbox
      </a>
    </div>
    
  </div>

    <br>
</div>

<footer class="container-fluid wm-page-content">
      <p>
        <a href="https://github.com/kauri-io/archive/edit/main/docs/collections/Build your very own self-hosting platform with Raspberry Pi and Kubernetes/(58)-self-host-your-media-center-on-kubernetes-wi.md"><i class="fa fa-github"></i>
Edit on GitHub</a>
      </p>
  <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a> using <a href="https://github.com/gristlabs/mkdocs-windmill">Windmill</a> theme by Grist Labs.</p>
</footer>

</body>
</html>